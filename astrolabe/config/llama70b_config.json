{
	"replica_config": {
		"model_name": "meta-llama/Llama-2-70b-hf",
		"memory_margin_fraction": 0.1,
		"num_pipeline_stages": 1,
		"tensor_parallel_size": 4,
		"device": "a100",
		"network_device": "a100_pairwise_nvlink"
	},
	"replica_scheduler_config": {
		"max_tokens_in_batch": 4096,
		"batch_size_cap": 32,
		"chunk_size": 512,
		"num_blocks": 2048
	},
	"target_metric": "min_new_request_latency",
	"enable_batch_time_estimation": true
}
