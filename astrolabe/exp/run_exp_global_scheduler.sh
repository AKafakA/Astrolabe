HOST=$1
M=$2
N=$3
METRICS_TYPE=$4
CONFIG_PATH=$5
NUM_WORKERS=$6
NUM_PREDICTORS=$7
PROFILING_SAMPLE_RATE=$8
BACKEND_TIMEOUT=$9
PREDICTOR_TIMEOUT=${10}
AVAILABLE_INSTANCE=${11}
MAX_SLO=${12}
ENABLE_PREEMPTIVE_AUTO_PROVISIONING=${13}
# Error injection parameters for sensitivity analysis (optional, default 0)
LENGTH_ERROR_PCT=${14:-0}
LATENCY_ERROR_PCT=${15:-0}

parallel-ssh -t 0 --host $HOST "pkill -f global_scheduler"
sleep 10

# Build error injection args if specified
ERROR_ARGS=""
if [ "$LENGTH_ERROR_PCT" != "0" ]; then
  ERROR_ARGS="$ERROR_ARGS --length_error_pct $LENGTH_ERROR_PCT"
fi
if [ "$LATENCY_ERROR_PCT" != "0" ]; then
  ERROR_ARGS="$ERROR_ARGS --latency_error_pct $LATENCY_ERROR_PCT"
fi

if [ "$ENABLE_PREEMPTIVE_AUTO_PROVISIONING" = "true" ]; then
  parallel-ssh -t 0 --host $HOST "cd Astrolabe && export PYTHONPATH=. && nohup python astrolabe/global_scheduler/api_server.py --config_path $CONFIG_PATH --metrics_type $METRICS_TYPE --num_query_predictor $M --num_required_predictor $N --workers $NUM_WORKERS --num_predictor_ports $NUM_PREDICTORS --profiling_sampling_rate $PROFILING_SAMPLE_RATE --predictor_timeout $PREDICTOR_TIMEOUT --backend_timeout $BACKEND_TIMEOUT --initial_available_instance $AVAILABLE_INSTANCE --max_slo_in_seconds $MAX_SLO --use_preemptive_provisioning $ERROR_ARGS > experiment_output/logs/global_scheduler.log 2>&1 &"
else
  parallel-ssh -t 0 --host $HOST "cd Astrolabe && export PYTHONPATH=. && nohup python astrolabe/global_scheduler/api_server.py --config_path $CONFIG_PATH --metrics_type $METRICS_TYPE --num_query_predictor $M --num_required_predictor $N --workers $NUM_WORKERS --num_predictor_ports $NUM_PREDICTORS --profiling_sampling_rate $PROFILING_SAMPLE_RATE --predictor_timeout $PREDICTOR_TIMEOUT --backend_timeout $BACKEND_TIMEOUT --initial_available_instance $AVAILABLE_INSTANCE --max_slo_in_seconds $MAX_SLO $ERROR_ARGS > experiment_output/logs/global_scheduler.log 2>&1 &"
fi